---
title: Main Conference Keynotes 
layout: single
excerpt: "EMNLP 2023 Keynote Speakers."
permalink: /program/keynotes/
toc: true
toc_sticky: true
toc_icon: "cog"
sidebar: 
    nav: program
---

We are delighted to announce that the esteemed speakers listed below have graciously accepted our invitation to deliver keynote speeches at the main conference of EMNLP 2023:

<style>
p.speaker-bio { font-style: italic; font-size: 80%; }
</style>

<!-- ### Humans Learn From Task Descriptions and So Should Our Models
*Main Conference Keynote<br>Monday, June 7, 08:00--09:00 PDT*

Joint work with Timo Schick and Sahana Udupa

Task descriptions are ubiquitous in human learning.  They are usually accompanied by a few examples, but there is little human learning that is based on examples only. In contrast, the typical learning setup for NLP tasks lacks task descriptions and is supervised with 100s or 1000s of examples.

We introduce Pattern-Exploiting Training (PET), an approach to learning that mimicks human learning in that it leverages task descriptions in few-shot settings.  PET is built on top
of a pretrained language model that "understands" the task description, especially after finetuning, resulting in excellent performance compared to other few-shot methods. In particular, a model trained with PET outperforms GPT-3 even though it has 99.9% fewer parameters.

In the last part of the talk, I will show how bias in NLP models can be addressed using task descriptions. Instructing a model to reveal and reduce its biases is remarkably effective and may contribute in the future to a fairer and more inclusive NLP. -->

## Speaker: Christopher D. Manning 

![Mona Diab](/assets/images/keynotes/Christopher_Manning.jpg){: .align-center}

### Academic NLP research in the Age of LLMs: Nothing but blue skies!


Christopher Manning is the inaugural Thomas M. Siebel Professor in Machine Learning in the Departments of Linguistics and Computer Science at Stanford University, Director of the Stanford Artificial Intelligence Laboratory (SAIL), and an Associate Director of the Stanford Institute for Human-Centered Artificial Intelligence (HAI). His research goal is computers that can intelligently process, understand, and generate human languages. Manning was an early leader in applying Deep Learning to Natural Language Processing (NLP), with well-known research on the GloVe model of word vectors, attention, machine translation, question answering, self-supervised model pre-training, tree-recursive neural networks, machine reasoning, dependency parsing, sentiment analysis, and summarization. He also focuses on computational linguistic approaches to parsing, natural language inference and multilingual language processing, including being a principal developer of Stanford Dependencies and Universal Dependencies. Manning has coauthored leading textbooks on statistical approaches to NLP (Manning and Schütze 1999) and information retrieval (Manning, Raghavan, and Schütze, 2008), as well as linguistic monographs on ergativity and complex predicates. His online CS224N Natural Language Processing with Deep Learning videos have been watched by hundreds of thousands of people. He is an ACM Fellow, a AAAI Fellow, and an ACL Fellow, and a Past President of the ACL (2015). His research has won ACL, Coling, EMNLP, and CHI Best Paper Awards, and an ACL Test of Time Award. He has a B.A. (Hons) from The Australian National University and a Ph.D. from Stanford in 1994, and an Honorary Doctorate from U. Amsterdam in 2023, and he held faculty positions at Carnegie Mellon University and the University of Sydney before returning to Stanford. He is the founder of the Stanford NLP group (@stanfordnlp) and manages development of the Stanford CoreNLP and Stanza software.
{: .speaker-bio}

Affiliation: Stanford University
{: .speaker-bio}

## Speaker: Emily Mower Provost

![Neil Cohn](/assets/images/keynotes/Emily_Provost.jpg){: .align-center}

### From Speech to Emotion to Mood: Mental Health Modeling in Real-World Environments.


Emily Mower Provost is a Professor in Computer Science and Engineering at the University of Michigan. She received her Ph.D. in Electrical Engineering from the University of Southern California (USC), Los Angeles, CA in 2010. She is a Toyota Faculty Scholar (2020) and has been awarded a National Science Foundation CAREER Award (2017), the Oscar Stern Award for Depression Research (2015), a National Science Foundation Graduate Research Fellowship (2004-2007).  She is an Associate Editor for IEEE Transactions on Affective Computing and the IEEE Open Journal of Signal Processing.  She has also served as Associate Editor for Computer Speech and Language and ACM Transactions on Multimedia.  She has received best paper awards or finalist nominations for Interspeech 2008, ACM Multimedia 2014, ICMI 2016, and IEEE Transactions on Affective Computing.  Among other organizational duties, she has been Program Chair for ACII (2017, 2021), ICMI (2016, 2018).  Her research interests are in human-centered speech and video processing, multimodal interfaces design, and speech-based assistive technology. The goals of her research are motivated by the complexities of the perception and expression of human behavior.
{: .speaker-bio}

Affiliation: University of Michigan
{: .speaker-bio}

## Speaker: Jong Park

![Gary Marcus](/assets/images/keynotes/Jong_Park.jpg){: .align-center}


### Human-Centric Natural Language Processing



Jong Park received his BE and MSE degrees from Seoul National University and PhD degree from the University of Pennsylvania, Philadelphia. He has been working as Assistant, Associate and Full Professor at Korea Advanced Institute of Science and Technology (KAIST) since 1998. He is one of the early researchers on BioNLP, applying NLP techniques to biology and medicine. His research team at KAIST has also been working broadly on identifying emotion from text, turning spoken language into visual animation and sign language, identifying mental health issues such as mild-cognitive impairment (MCI) and clinical depression from natural language utterances, detecting abusive language, and, more recently, credibility assessment and bidirectional sign language processing. His team has received Outstanding Paper Award at ACL 2023 for the work on the Tigrinya language. He is serving as founding Editor-in-Chief of Journal of Computing Science and Engineering (JCSE) since 2007, President of Asian Federation of Natural Language Processing (AFNLP) during 2022~2024, and General Chair of IJCNLP-AACL 2023. 
{: .speaker-bio}

Affiliation: Korea Advanced Institute of Science and Technology (KAIST)
{: .speaker-bio}

<!--## Dhruv Batra

![Dhruv Batra](/assets/images/keynotes/Dhruv_Batra.jpg){: .align-center}

### From Disembodied to Embodied Multimodal Learning
*Main Conference Keynote<br>Monday, June 7, 16:00--17:00 PDT*

Embodied AI is the science and engineering of intelligent machines with a physical or virtual embodiment (e.g., robots and egocentric personal assistants). Imagine walking up to a home assistant robot and asking “Hey robot – can you go check if my laptop is on my desk? And if so, bring it to me”. Or asking an egocentric AI assistant (operating on your smart glasses): “Hey – where did I last see my keys?”. The embodiment hypothesis is the idea that “intelligence emerges in the interaction of an agent with an environment and as a result of sensorimotor activity”. In this talk, I will argue that we should take the embodiment hypothesis (and it implications) seriously. And I will weave through a line of work happening at my group at Georgia Tech and with collaborators at FAIR illustrating the shift from disembodied vision-and-language (multimodal) agents towards such embodied agents.

Dhruv Batra is an Associate Professor in the School of Interactive Computing at Georgia Tech and a Research Scientist at Facebook AI Research (FAIR). His research interests lie at the intersection of machine learning, computer vision, natural language processing, and AI. The long-term goal of his research is to develop agents that 'see' (or more generally perceive their environment through vision, audition, or other senses), 'talk' (i.e. hold a natural language dialog grounded in their environment), 'act' (e.g. navigate their environment and interact with it to accomplish goals), and 'reason' (i.e., consider the long-term consequences of their actions). He is a recipient of the Presidential Early Career Award for Scientists and Engineers (PECASE) 2019. ([Full Biography](https://www.cc.gatech.edu/~dbatra/files/bio.txt))
{: .speaker-bio}


## Shakir Mohamed

![Shakir Mohamed](/assets/images/keynotes/Shakir_Mohamed.jpg){: .align-center}

### Generating Reality: Technical and Social Explorations in Generative Machine Learning Research
*Main Conference Keynote<br>Tuesday, June 8, 08:00--09:00 PDT*

We are going to play with the meaning and implications of the word ‘generative’ in this talk. A generative approach to machine learning is now widely-established, and we now have techniques to generate, simulate, confabulate and fake all sorts of data we can find, natural language included. Using my own research, I’d like to review the statistical foundations of this generative approach and some of the questions that still seem open to us. Yet, no act of generation exists outside of the social world. So, I’d like to also explore how these technical questions are instead social questions. I’d again like to use my own experience to explore the sociotechnical theories that can direct us towards a more critical practice of machine learning. This leads to a generative field of machine learning that transforms criticism into productive alternatives: a field that continues to seek creative solutions for challenging problems, but is more deeply embedded, concerned and responsible for the new technological realities it seeks to generate.

Dr Shakir Mohamed works on technical and sociotechnical questions in machine learning research, aspiring to make contributions to machine learning principles, applied problems in healthcare and environment, and ethics and diversity. Shakir is a research scientist and lead at DeepMind in London, an Associate Fellow at the Leverhulme Centre for the Future of Intelligence, and a Honorary Professor of University College London. Shakir is also a founder and trustee of the Deep Learning Indaba, a grassroots organisation aiming to build pan-African capacity and leadership in AI. Shakir was the General Chair for the 2021 International conference on Learning Representations, and a member of the Royal Society's Diversity Committee.
{: .speaker-bio}


## Thamar Solorio

![Thamar Solorio](/assets/images/keynotes/Thamar_Solorio.jpg){: .align-center}

### Moving the needle in NLP technology for the processing of code-switched language
*Main Conference Keynote<br>Tuesday, June 8, 16:00--17:00 PDT*

Multilingual speakers are known to mix their languages when communicating with other multilingual speakers in what is called code-switching. While worldwide monolingual speakers are outnumbered by multilingual ones, most of the NLP technologies being developed nowadays target monolingual speakers of a handful of languages. This is also true of multilingual models that, although designed to process many languages, still assume a one language per input setting. These multilingual models have been shown to decrease performance when the input has code-switching in several tasks, including language identification, part of speech tagging, named entity recognition and machine translation.  In this talk, I will give an overview of recent work that aims to address the linguistic challenges that code-switching poses to state of the art models, where the goal is to leverage pretrained models from high resource languages. This code-switching research is part of my long term goal of increasing the coverage of human language abilities by NLP technologies, disrupting the status quo of non-equitable systems.

Thamar Solorio is an Associate Professor of the Department of Computer Science at the University of Houston (UH). She holds graduate degrees in Computer Science from the Instituto Nacional de Astrofísica, Óptica y Electrónica, in Puebla, Mexico. Her research interests include information extraction from social media data, enabling technology for code-switched data, stylistic modeling of text and more recently multimodal approaches to online content understanding. She is the director and founder of the Research in Text Understanding and Language Analysis Lab at UH. She is the recipient of an NSF CAREER award for her work on authorship attribution, and recipient of the 2014 Emerging Leader ABIE Award in Honor of Denice Denton. She is an elected board member of the North American Chapter of the Association of Computational Linguistics (2020-2021). Her research is currently funded by the National Science Foundation and ADOBE, and in the past she has received support from the Office of Naval Research and the Defense Advanced Research Projects Agency (DARPA).
{: .speaker-bio}


## Aya Soffer

![Aya Soffer](/assets/images/keynotes/Aya_Soffer.jpg){: .align-center}

### Project Debater - from grand challenge to business applications, behind the scenes and lessons learned
*Industry Track Keynote<br>Wednesday, June 9, 08:00--09:00 PDT*

Project Debater started as an IBM grand challenge idea in 2011, and eventually competed on stage with a world-renowned debater in 2019. The team has since been further developing the underlying technology, applying it to various business use cases, and is providing access to the underlying tech for non-commercial use. In this talk I will provide a behind the scenes perspective on developing such a project from an idea to a machine that can debate humans, highlight some of the technical innovations including the recent publication in Nature, and discuss various business applications of the technology and how it fits in the overall Language Strategy for IBM Research.

Dr. Aya Soffer is Vice President of AI Technologies for the IBM Research AI organization and the Director of the IBM Research - Haifa lab. Her Research focus is natural language understanding and conversational systems and their application in customer care and other enterprise applications. In this role Dr. Soffer is responsible for setting the strategy and working with IBM scientists around the world to shape their ideas into new AI technology, and with IBM’s product groups and customers to drive Research innovation into the market.  In her 20 years at IBM, Dr. Soffer has led several strategic initiatives that grew into successful IBM products and solutions in the Big Data and AI space including the original Watson system and more recently Project Debater. She has authored over 50 peer-reviewed papers and served as an invited speaker in numerous conferences.
{: .speaker-bio}


## Dan Weld

![Dan Weld](/assets/images/keynotes/Dan_Weld.jpg){: .align-center}

### Semantic Scholar - Advanced NLP to Accelerate Scientific Research
*Industry Track Keynote<br>Wednesday, June 9, 16:00--17:00 PDT*

Semantic Scholar (S2) is a 40 person effort at the Allen Institute for Artificial Intelligence that drives a website used by almost 100M people each year. Our mission is to accelerate the progress of scientific research with augmented intelligence - advanced tools that make it easier to find relevant research, digest it quickly, and make connections between different problems and approaches. This talk will survey some of the NLP advances underlying S2, from the identification of emerging scientific concepts to extreme abstractive summarization, full-document understanding, and fact checking.

Daniel S. Weld is Thomas J. Cable / WRF Professor in the Paul G. Allen School of Computer Science & Engineering, manages the Semantic Scholar research group at the Allen Institute of Artificial Intelligence, and is Venture Partner at the Madrona Venture Group.  After formative education at Phillips Academy, he received bachelor's degrees in both Computer Science and Biochemistry at Yale University in 1982. He landed a Ph.D. from the MIT Artificial Intelligence Lab in 1988, received a Presidential Young Investigator's award in 1989, an Office of Naval Research Young Investigator's award in 1990, was named AAAI Fellow in 1999 and deemed ACM Fellow in 2005. Dan was a founding editor for the Journal of AI Research, was area editor for the Journal of the ACM.  Dan has co-founded three companies, Netbot (sold to Excite), Adrelevance (sold to Media Metrix), and Nimble technology (sold to Actuate).
{: .speaker-bio}-->



